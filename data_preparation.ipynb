{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "from transformers import Wav2Vec2Processor\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Filtering out clips with non-stuttering events...\n",
      "Remaining clips after filtering: 20851\n",
      "\n",
      "Class distribution after applying new criteria:\n",
      "Fluent: 4434 samples (21.27%)\n",
      "Dysfluent: 16417 samples (78.73%)\n",
      "\n",
      "Dysfluency type distribution:\n",
      "Prolongation: 6360 samples (30.50%)\n",
      "Block: 8484 samples (40.69%)\n",
      "SoundRep: 3680 samples (17.65%)\n",
      "WordRep: 3625 samples (17.39%)\n",
      "Interjection: 7522 samples (36.08%)\n",
      "Combined Repetition: 6175 samples (29.61%)\n",
      "\n",
      "SetID column not found. Creating a SetID column for splitting.\n",
      "\n",
      "Training samples: 14595\n",
      "Validation samples: 3127\n",
      "Testing samples: 3129\n",
      "\n",
      "Loading Wav2Vec2 processor...\n",
      "Extracting features for train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 35/14595 [00:00<00:43, 335.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\HeStutters_0_0.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_2.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_3.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_4.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_5.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_6.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_7.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_8.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_10.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_12.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_14.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_15.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_22.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_24.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_25.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_29.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_31.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_32.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_33.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_34.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_35.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_36.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_37.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_38.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_39.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_15.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_16.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_20.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_22.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_23.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_24.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_26.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_33.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_36.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_38.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_39.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_49.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_50.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_51.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_52.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_65.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_66.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_67.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_70.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_75.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_77.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_78.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_82.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_86.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_87.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_88.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_91.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_98.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_99.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_100.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_103.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4795/14595 [00:54<01:18, 124.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_0.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_1.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_2.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_3.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_6.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_9.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_10.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_11.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_13.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_14.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_15.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_18.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_20.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_21.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_22.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_24.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_25.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_26.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_30.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_31.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_32.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_33.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_34.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_35.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_38.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_39.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 7214/14595 [01:25<01:32, 79.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\StutterTalk_59_31.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StutterTalk_59_34.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StutterTalk_59_35.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StutterTalk_59_36.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 9928/14595 [02:07<00:38, 121.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_31.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_36.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_39.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_45.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_46.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_49.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_50.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_53.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_55.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_71.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_72.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_77.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_78.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_82.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_92.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_105.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_109.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_110.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_111.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_124.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_128.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_129.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_134.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_135.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14595/14595 [03:21<00:00, 72.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for val split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/3127 [00:00<00:25, 124.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\HeStutters_0_1.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_27.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_28.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_25.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_59.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_63.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_101.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1058/3127 [00:16<00:30, 68.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_17.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_27.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_28.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_36.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1531/3127 [00:23<00:26, 59.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\StutterTalk_59_37.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 2121/3127 [00:33<00:14, 67.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_40.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_63.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3127/3127 [00:49<00:00, 62.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for test split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/3129 [00:00<00:25, 122.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\HeStutters_0_9.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_11.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_13.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_0_16.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_32.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_43.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\HeStutters_1_85.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1026/3129 [00:13<00:27, 75.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_8.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_12.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StrongVoices_25_23.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1541/3129 [00:20<00:20, 78.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\StutterTalk_59_33.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\StutterTalk_59_38.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 2133/3129 [00:28<00:11, 83.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_51.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_56.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_59.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_60.wav: Failed to decode audio.\n",
      "Error processing Dataset\\SEP-28K\\WomenWhoStutter_0_112.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3129/3129 [00:41<00:00, 74.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete!\n",
      "Upload the 'processed_features' folder to Colab to continue with model training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_features_locally():\n",
    "    print(\"Loading dataset...\")\n",
    "    df = pd.read_csv('Dataset/SEP-28k_labels.csv')\n",
    "    \n",
    "    # Define non-stuttering event labels to filter out\n",
    "    non_stutter_events = [\n",
    "        'Music', \n",
    "        'NoSpeech', \n",
    "        'Unsure', \n",
    "        'DifficultToUnderstand', \n",
    "        'PoorAudioQuality'\n",
    "    ]\n",
    "    \n",
    "    # Filter out clips with any non-stuttering events (count > 0)\n",
    "    print(\"Filtering out clips with non-stuttering events...\")\n",
    "    for event in non_stutter_events:\n",
    "        if event in df.columns:\n",
    "            df = df[df[event] == 0]\n",
    "    \n",
    "    print(f\"Remaining clips after filtering: {len(df)}\")\n",
    "    \n",
    "    # Define the dysfluency labels using actual column names\n",
    "    dysfluency_labels = ['Prolongation', 'Block', 'SoundRep', 'WordRep', 'Interjection']\n",
    "    \n",
    "    # Create binary labels for each dysfluency type (count > 0)\n",
    "    for label in dysfluency_labels:\n",
    "        df[f'{label}_binary'] = (df[label] > 0).astype(int)\n",
    "    \n",
    "    # Create a combined repetition binary label (SoundRep OR WordRep)\n",
    "    df['Repetition_binary'] = ((df['SoundRep'] > 0) | (df['WordRep'] > 0)).astype(int)\n",
    "    \n",
    "    # Create the fluent/dysfluent binary label\n",
    "    # A clip is fluent if NoStutteredWords > 0 or if all dysfluency types have count = 0\n",
    "    has_any_dysfluency = (df[['Prolongation', 'Block', 'SoundRep', 'WordRep', 'Interjection']] > 0).any(axis=1).astype(int)\n",
    "    df['Fluent_binary'] = (~has_any_dysfluency.astype(bool)).astype(int)  # 1 means fluent, 0 means dysfluent\n",
    "    \n",
    "    # Print class distribution\n",
    "    print(\"\\nClass distribution after applying new criteria:\")\n",
    "    total = len(df)\n",
    "    print(f\"Fluent: {df['Fluent_binary'].sum()} samples ({df['Fluent_binary'].sum()/total*100:.2f}%)\")\n",
    "    print(f\"Dysfluent: {total - df['Fluent_binary'].sum()} samples ({(total - df['Fluent_binary'].sum())/total*100:.2f}%)\")\n",
    "    \n",
    "    print(\"\\nDysfluency type distribution:\")\n",
    "    for label in dysfluency_labels:\n",
    "        binary_col = f'{label}_binary'\n",
    "        positive_count = df[binary_col].sum()\n",
    "        print(f\"{label}: {positive_count} samples ({positive_count/total*100:.2f}%)\")\n",
    "    print(f\"Combined Repetition: {df['Repetition_binary'].sum()} samples ({df['Repetition_binary'].sum()/total*100:.2f}%)\")\n",
    "    \n",
    "    # Create a SetID if it doesn't exist\n",
    "    if 'SetID' not in df.columns:\n",
    "        print(\"\\nSetID column not found. Creating a SetID column for splitting.\")\n",
    "        # Group by unique clips\n",
    "        unique_clips = df[['Show', 'EpId', 'ClipId']].drop_duplicates()\n",
    "        \n",
    "        # Assign 1-10 for train, 11-20 for val, 21-30 for test, with appropriate distributions\n",
    "        num_train = int(len(unique_clips) * 0.7)\n",
    "        num_val = int(len(unique_clips) * 0.15)\n",
    "        \n",
    "        # Shuffle the clips\n",
    "        unique_clips = unique_clips.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        # Assign SetIDs\n",
    "        unique_clips.loc[:num_train-1, 'SetID'] = np.random.randint(1, 11, size=num_train)\n",
    "        unique_clips.loc[num_train:num_train+num_val-1, 'SetID'] = np.random.randint(11, 21, size=num_val)\n",
    "        unique_clips.loc[num_train+num_val:, 'SetID'] = np.random.randint(21, 31, size=len(unique_clips)-num_train-num_val)\n",
    "        \n",
    "        # Merge back to get SetID for all rows\n",
    "        df = pd.merge(df, unique_clips, on=['Show', 'EpId', 'ClipId'])\n",
    "    \n",
    "    # Split data according to SetID\n",
    "    train_df = df[df['SetID'].isin(range(1, 11))]\n",
    "    val_df = df[df['SetID'].isin(range(11, 21))]\n",
    "    test_df = df[df['SetID'].isin(range(21, 31))]\n",
    "    \n",
    "    # If the split doesn't work, fall back to random split\n",
    "    if len(train_df) == 0 or len(val_df) == 0 or len(test_df) == 0:\n",
    "        print(\"SetID doesn't match expected pattern. Using a random split.\")\n",
    "        unique_clips = df[['Show', 'EpId', 'ClipId']].drop_duplicates()\n",
    "        train_clips, temp_clips = train_test_split(unique_clips, test_size=0.3, random_state=42)\n",
    "        val_clips, test_clips = train_test_split(temp_clips, test_size=0.5, random_state=42)\n",
    "        \n",
    "        # Merge back to get the full data for each split\n",
    "        train_df = pd.merge(df, train_clips, on=['Show', 'EpId', 'ClipId'])\n",
    "        val_df = pd.merge(df, val_clips, on=['Show', 'EpId', 'ClipId'])\n",
    "        test_df = pd.merge(df, test_clips, on=['Show', 'EpId', 'ClipId'])\n",
    "    \n",
    "    print(f\"\\nTraining samples: {len(train_df)}\")\n",
    "    print(f\"Validation samples: {len(val_df)}\")\n",
    "    print(f\"Testing samples: {len(test_df)}\")\n",
    "    \n",
    "    # Create directories for saving features\n",
    "    os.makedirs('processed_features', exist_ok=True)\n",
    "    os.makedirs('processed_features/train', exist_ok=True)\n",
    "    os.makedirs('processed_features/val', exist_ok=True)\n",
    "    os.makedirs('processed_features/test', exist_ok=True)\n",
    "    \n",
    "    # Save the label dataframes\n",
    "    train_df.to_csv('processed_features/train_labels.csv', index=False)\n",
    "    val_df.to_csv('processed_features/val_labels.csv', index=False)\n",
    "    test_df.to_csv('processed_features/test_labels.csv', index=False)\n",
    "    \n",
    "    # For the combined model:\n",
    "    # We'll use these labels for multi-label classification\n",
    "    dysfluency_labels_for_model = ['Repetition_binary', 'Prolongation_binary', 'Block_binary', 'Interjection_binary']\n",
    "    \n",
    "    # Calculate class weights for multi-label classification\n",
    "    weights = []\n",
    "    total_samples = len(train_df)\n",
    "    for label in dysfluency_labels_for_model:\n",
    "        positive_count = train_df[label].sum()\n",
    "        if positive_count > 0:\n",
    "            weight = total_samples / (2 * positive_count)\n",
    "        else:\n",
    "            weight = 1.0\n",
    "        weights.append(weight)\n",
    "    \n",
    "    # Map back to original label names for clarity\n",
    "    label_names = ['Repetition', 'Prolongation', 'Block', 'Interjection']\n",
    "    \n",
    "    # Save the class weights\n",
    "    with open('processed_features/class_weights.json', 'w') as f:\n",
    "        json.dump({label: float(weight) for label, weight in zip(label_names, weights)}, f)\n",
    "    \n",
    "    # Load Wav2Vec2 processor\n",
    "    print(\"\\nLoading Wav2Vec2 processor...\")\n",
    "    processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    \n",
    "    # Function to extract and save features for a dataframe\n",
    "    def extract_features_for_split(dataframe, split_name, audio_dir):\n",
    "        print(f\"Extracting features for {split_name} split...\")\n",
    "        \n",
    "        # Dictionary to store file paths and labels\n",
    "        split_data = {\n",
    "            'file_paths': [],\n",
    "            'binary_labels': [],\n",
    "            'multi_labels': []\n",
    "        }\n",
    "        \n",
    "        for idx, row in tqdm(dataframe.iterrows(), total=len(dataframe)):\n",
    "            # Construct filename with proper underscores\n",
    "            show = row['Show']\n",
    "            ep_id = row['EpId']\n",
    "            clip_id = row['ClipId']\n",
    "            filename = f\"{show}_{ep_id}_{clip_id}.wav\"\n",
    "            audio_path = os.path.join(audio_dir, filename)\n",
    "            \n",
    "            feature_path = f\"processed_features/{split_name}/{show}_{ep_id}_{clip_id}.pt\"\n",
    "            \n",
    "            # Skip if features already exist\n",
    "            if os.path.exists(feature_path):\n",
    "                # Add to the split data\n",
    "                split_data['file_paths'].append(feature_path)\n",
    "                split_data['binary_labels'].append(row['Fluent_binary'])\n",
    "                split_data['multi_labels'].append([row[label] for label in dysfluency_labels_for_model])\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Load audio\n",
    "                waveform, sample_rate = torchaudio.load(audio_path)\n",
    "                \n",
    "                # Convert to mono if stereo\n",
    "                if waveform.shape[0] > 1:\n",
    "                    waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "                \n",
    "                # Resample if needed (Wav2Vec2 expects 16kHz)\n",
    "                if sample_rate != 16000:\n",
    "                    resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "                    waveform = resampler(waveform)\n",
    "                \n",
    "                # Squeeze to remove channel dimension\n",
    "                waveform = waveform.squeeze(0)\n",
    "                \n",
    "                # Process with Wav2Vec2\n",
    "                inputs = processor(waveform, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "                \n",
    "                # Save processed features\n",
    "                torch.save(inputs, feature_path)\n",
    "                \n",
    "                # Add to the split data\n",
    "                split_data['file_paths'].append(feature_path)\n",
    "                split_data['binary_labels'].append(row['Fluent_binary'])\n",
    "                split_data['multi_labels'].append([row[label] for label in dysfluency_labels_for_model])\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {audio_path}: {e}\")\n",
    "        \n",
    "        # Save the split data\n",
    "        with open(f'processed_features/{split_name}_data.pkl', 'wb') as f:\n",
    "            pickle.dump(split_data, f)\n",
    "    \n",
    "    # Extract features for each split\n",
    "    audio_dir = \"Dataset\\\\SEP-28K\"  # Update with your local path\n",
    "    extract_features_for_split(train_df, 'train', audio_dir)\n",
    "    extract_features_for_split(val_df, 'val', audio_dir)\n",
    "    extract_features_for_split(test_df, 'test', audio_dir)\n",
    "    \n",
    "    # Save the label information for the model\n",
    "    label_info = {\n",
    "        'binary_label': 'Fluent_binary',\n",
    "        'multi_labels': dysfluency_labels_for_model,\n",
    "        'label_names': label_names\n",
    "    }\n",
    "    with open('processed_features/label_info.json', 'w') as f:\n",
    "        json.dump(label_info, f)\n",
    "    \n",
    "    print(\"Feature extraction complete!\")\n",
    "    print(\"Upload the 'processed_features' folder to Colab to continue with model training.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_features_locally()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "from transformers import Wav2Vec2Processor\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs('fluencybank_processed_features', exist_ok=True)\n",
    "os.makedirs('fluencybank_processed_features/train', exist_ok=True)\n",
    "os.makedirs('fluencybank_processed_features/val', exist_ok=True)\n",
    "os.makedirs('fluencybank_processed_features/test', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FluencyBank dataset...\n",
      "Filtering out clips with non-stuttering events...\n",
      "Remaining clips after filtering: 3624\n"
     ]
    }
   ],
   "source": [
    "# Load FluencyBank annotations\n",
    "print(\"Loading FluencyBank dataset...\")\n",
    "fluencybank_df = pd.read_csv('Dataset/fluencybank_labels.csv')\n",
    "\n",
    "# Define non-stuttering event labels to filter out\n",
    "non_stutter_events = [\n",
    "    'Music', \n",
    "    'NoSpeech', \n",
    "    'Unsure', \n",
    "    'DifficultToUnderstand', \n",
    "    'PoorAudioQuality'\n",
    "]\n",
    "\n",
    "# Filter out clips with any non-stuttering events (count > 0)\n",
    "print(\"Filtering out clips with non-stuttering events...\")\n",
    "for event in non_stutter_events:\n",
    "    if event in fluencybank_df.columns:\n",
    "        fluencybank_df = fluencybank_df[fluencybank_df[event] == 0]\n",
    "\n",
    "print(f\"Remaining clips after filtering: {len(fluencybank_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining SoundRep and WordRep into Repetition...\n",
      "\n",
      "Class distribution after applying new criteria:\n",
      "Fluent: 931 samples (25.69%)\n",
      "Dysfluent: 2693 samples (74.31%)\n",
      "\n",
      "Dysfluency type distribution:\n",
      "Repetition: 1424 samples (39.29%)\n",
      "Prolongation: 814 samples (22.46%)\n",
      "Block: 1192 samples (32.89%)\n",
      "Interjection: 1484 samples (40.95%)\n"
     ]
    }
   ],
   "source": [
    "# Handle SoundRep and WordRep combination\n",
    "# Create a combined 'Repetition' column if SoundRep and WordRep exist separately\n",
    "if 'SoundRep' in fluencybank_df.columns and 'WordRep' in fluencybank_df.columns:\n",
    "    print(\"Combining SoundRep and WordRep into Repetition...\")\n",
    "    fluencybank_df['Repetition'] = fluencybank_df[['SoundRep', 'WordRep']].max(axis=1)\n",
    "    dysfluency_labels = ['Repetition', 'Prolongation', 'Block', 'Interjection']\n",
    "else:\n",
    "    # If they're already combined or have different names\n",
    "    dysfluency_labels = [col for col in ['Repetition', 'Prolongation', 'Block', 'Interjection'] \n",
    "                        if col in fluencybank_df.columns]\n",
    "\n",
    "# Create binary labels for each dysfluency type (count > 0)\n",
    "for label in dysfluency_labels:\n",
    "    fluencybank_df[f'{label}_binary'] = (fluencybank_df[label] > 0).astype(int)\n",
    "\n",
    "# Create binary fluent/dysfluent label\n",
    "has_any_dysfluency = (fluencybank_df[[f'{label}_binary' for label in dysfluency_labels]].sum(axis=1) > 0).astype(int)\n",
    "fluencybank_df['Fluent_binary'] = (~has_any_dysfluency.astype(bool)).astype(int)\n",
    "\n",
    "# Print class distribution\n",
    "print(\"\\nClass distribution after applying new criteria:\")\n",
    "total = len(fluencybank_df)\n",
    "print(f\"Fluent: {fluencybank_df['Fluent_binary'].sum()} samples ({fluencybank_df['Fluent_binary'].sum()/total*100:.2f}%)\")\n",
    "print(f\"Dysfluent: {total - fluencybank_df['Fluent_binary'].sum()} samples ({(total - fluencybank_df['Fluent_binary'].sum())/total*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nDysfluency type distribution:\")\n",
    "for label in dysfluency_labels:\n",
    "    binary_col = f'{label}_binary'\n",
    "    positive_count = fluencybank_df[binary_col].sum()\n",
    "    print(f\"{label}: {positive_count} samples ({positive_count/total*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2536\n",
      "Validation samples: 544\n",
      "Testing samples: 544\n"
     ]
    }
   ],
   "source": [
    "# Split data into train, val, test sets\n",
    "# Create filename by combining columns with proper formatting\n",
    "fluencybank_df['filename'] = fluencybank_df.apply(\n",
    "    lambda row: f\"FluencyBank_{str(row['EpId']).zfill(3)}_{row['ClipId']}.wav\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Now split using this constructed filename\n",
    "unique_files = fluencybank_df[['filename']].drop_duplicates()\n",
    "\n",
    "train_files, temp_files = train_test_split(unique_files, test_size=0.3, random_state=42)\n",
    "val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create dataframes for each split\n",
    "train_df = pd.merge(fluencybank_df, train_files, on=['filename'])\n",
    "val_df = pd.merge(fluencybank_df, val_files, on=['filename'])\n",
    "test_df = pd.merge(fluencybank_df, test_files, on=['filename'])\n",
    "\n",
    "# Save the label dataframes\n",
    "train_df.to_csv('fluencybank_processed_features/train_labels.csv', index=False)\n",
    "val_df.to_csv('fluencybank_processed_features/val_labels.csv', index=False)\n",
    "test_df.to_csv('fluencybank_processed_features/test_labels.csv', index=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Testing samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:\n",
      "Repetition: 1.2617\n",
      "Prolongation: 2.1712\n",
      "Block: 1.5259\n",
      "Interjection: 1.1940\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights for multi-label classification\n",
    "weights = []\n",
    "total_samples = len(train_df)\n",
    "for label in dysfluency_labels:\n",
    "    binary_col = f'{label}_binary'\n",
    "    positive_count = train_df[binary_col].sum()\n",
    "    if positive_count > 0:\n",
    "        weight = total_samples / (2 * positive_count)\n",
    "    else:\n",
    "        weight = 1.0\n",
    "    weights.append(weight)\n",
    "\n",
    "# Save the class weights\n",
    "with open('fluencybank_processed_features/class_weights.json', 'w') as f:\n",
    "    json.dump({label: float(weight) for label, weight in zip(dysfluency_labels, weights)}, f)\n",
    "\n",
    "print(\"Class weights:\")\n",
    "for label, weight in zip(dysfluency_labels, weights):\n",
    "    print(f\"{label}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Wav2Vec2 processor...\n"
     ]
    }
   ],
   "source": [
    "# Load Wav2Vec2 processor\n",
    "print(\"\\nLoading Wav2Vec2 processor...\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Function to extract and save features for a dataframe\n",
    "def extract_features_for_split(dataframe, split_name, audio_dir):\n",
    "    print(f\"Extracting features for {split_name} split...\")\n",
    "    \n",
    "    # Dictionary to store file paths and labels\n",
    "    split_data = {\n",
    "        'file_paths': [],\n",
    "        'binary_labels': [],\n",
    "        'multi_labels': []\n",
    "    }\n",
    "    \n",
    "    for idx, row in tqdm(dataframe.iterrows(), total=len(dataframe)):\n",
    "        # Construct filename based on FluencyBank naming conventions\n",
    "        # Adjust this part based on your actual audio file naming pattern\n",
    "        filename = row['filename']  # Change to your column name for audio filenames\n",
    "        audio_path = os.path.join(audio_dir, filename)\n",
    "        \n",
    "        feature_path = f\"fluencybank_processed_features/{split_name}/{filename.replace('.wav', '.pt')}\"\n",
    "        \n",
    "        # Skip if features already exist\n",
    "        if os.path.exists(feature_path):\n",
    "            # Add to the split data\n",
    "            split_data['file_paths'].append(feature_path)\n",
    "            split_data['binary_labels'].append(row['Fluent_binary'])\n",
    "            split_data['multi_labels'].append([row[f'{label}_binary'] for label in dysfluency_labels])\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Load audio\n",
    "            waveform, sample_rate = torchaudio.load(audio_path)\n",
    "            \n",
    "            # Convert to mono if stereo\n",
    "            if waveform.shape[0] > 1:\n",
    "                waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "            \n",
    "            # Resample if needed (Wav2Vec2 expects 16kHz)\n",
    "            if sample_rate != 16000:\n",
    "                resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "                waveform = resampler(waveform)\n",
    "            \n",
    "            # Squeeze to remove channel dimension\n",
    "            waveform = waveform.squeeze(0)\n",
    "            \n",
    "            # Process with Wav2Vec2\n",
    "            inputs = processor(waveform, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "            \n",
    "            # Save processed features\n",
    "            torch.save(inputs, feature_path)\n",
    "            \n",
    "            # Add to the split data\n",
    "            split_data['file_paths'].append(feature_path)\n",
    "            split_data['binary_labels'].append(row['Fluent_binary'])\n",
    "            split_data['multi_labels'].append([row[f'{label}_binary'] for label in dysfluency_labels])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {audio_path}: {e}\")\n",
    "    \n",
    "    # Save the split data\n",
    "    with open(f'fluencybank_processed_features/{split_name}_data.pkl', 'wb') as f:\n",
    "        pickle.dump(split_data, f)\n",
    "    \n",
    "    print(f\"Saved {len(split_data['file_paths'])} features for {split_name} split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\F'\n",
      "C:\\Users\\siddh\\AppData\\Local\\Temp\\ipykernel_27968\\610163419.py:2: SyntaxWarning: invalid escape sequence '\\F'\n",
      "  audio_dir = \"Dataset\\FluencyBank\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 221/2536 [00:02<00:14, 156.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_7.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_8.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_11.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_12.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_16.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_17.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_22.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_24.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_25.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_26.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_29.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_33.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_34.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_35.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_36.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_37.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_40.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_41.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_43.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_44.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_45.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_51.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_52.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_55.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_60.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_63.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_64.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_66.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_67.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_70.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_71.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_72.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_73.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_74.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_75.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_78.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_79.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1664/2536 [00:21<00:04, 181.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_5.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_6.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_8.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_9.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_10.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_12.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_14.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_19.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_20.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_21.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_22.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_23.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_24.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_25.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_26.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_27.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_28.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_31.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_33.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_34.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_35.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_36.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_40.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_42.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_43.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_44.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_47.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_48.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_49.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_51.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_53.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_54.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_55.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_56.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_61.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_63.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_66.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_67.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_68.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_69.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_70.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_71.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_72.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_75.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_76.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_77.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_78.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_80.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_82.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_83.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_84.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_85.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_86.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_88.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 1683/2536 [00:22<00:05, 148.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_91.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_92.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_93.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_94.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_99.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_101.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_104.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_105.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_108.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_109.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2536/2536 [00:38<00:00, 65.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2435 features for train split\n",
      "Extracting features for val split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 68/544 [00:01<00:05, 86.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_9.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_10.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_23.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_27.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_28.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_30.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_31.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_42.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_46.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_47.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_49.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_54.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_65.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 381/544 [00:07<00:02, 60.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_13.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_18.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_37.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_38.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_50.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_59.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_60.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_79.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_87.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_90.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 544/544 [00:11<00:00, 49.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 521 features for val split\n",
      "Extracting features for test split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 54/544 [00:01<00:06, 73.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_13.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_15.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_20.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_21.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_58.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_59.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_61.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_62.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_68.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_019_69.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 344/544 [00:07<00:03, 62.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_7.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_11.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_17.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_32.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_39.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_46.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_52.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_64.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_65.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_81.wav: Failed to decode audio.\n",
      "Error processing Dataset\\FluencyBank\\FluencyBank_118_100.wav: Failed to decode audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 544/544 [00:12<00:00, 44.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 523 features for test split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Update this path to point to your local FluencyBank audio files\n",
    "audio_dir = \"Dataset\\FluencyBank\"  \n",
    "\n",
    "# Process each split\n",
    "extract_features_for_split(train_df, 'train', audio_dir)\n",
    "extract_features_for_split(val_df, 'val', audio_dir)\n",
    "extract_features_for_split(test_df, 'test', audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete!\n",
      "Upload the 'fluencybank_processed_features' folder to Colab to continue with model training.\n"
     ]
    }
   ],
   "source": [
    "# Save the label information for the model\n",
    "label_info = {\n",
    "    'binary_label': 'Fluent_binary',\n",
    "    'multi_labels': [f'{label}_binary' for label in dysfluency_labels],\n",
    "    'label_names': dysfluency_labels\n",
    "}\n",
    "with open('fluencybank_processed_features/label_info.json', 'w') as f:\n",
    "    json.dump(label_info, f)\n",
    "\n",
    "print(\"Feature extraction complete!\")\n",
    "print(\"Upload the 'fluencybank_processed_features' folder to Colab to continue with model training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
